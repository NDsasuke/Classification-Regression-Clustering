{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1Nxoc6wgnI4CF+aAzVqJO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NDsasuke/Classification-Regression-Clustering/blob/main/Classification/Spam_recognition_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " import the necessary libraries:"
      ],
      "metadata": {
        "id": "nJh-lyf0RzTK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Y3vULs0rRvTL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "download the spam data:"
      ],
      "metadata": {
        "id": "BZqho4pyR6R2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv'\n",
        "df = pd.read_csv(url, usecols=[0,1], encoding='latin-1')\n",
        "df.columns = ['label', 'message']"
      ],
      "metadata": {
        "id": "DvwMNar0SAE_"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map 'spam' to 1 and 'ham' to 0"
      ],
      "metadata": {
        "id": "egdarI31SaiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df.label.map({'spam':1, 'ham':0})"
      ],
      "metadata": {
        "id": "c3TWVYaBSeS1"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into train and test sets"
      ],
      "metadata": {
        "id": "Ar_mLmWKSiAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['label'], test_size=0.2)\n"
      ],
      "metadata": {
        "id": "dk2U8Gy6SrlM"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the messages into frequency counts (bag of words model)"
      ],
      "metadata": {
        "id": "o9uQjxnWSsXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vect = CountVectorizer(stop_words='english', token_pattern=r'\\b[^\\d\\W]+\\b')\n",
        "X_train = vect.fit_transform(X_train)\n",
        "X_test = vect.transform(X_test)"
      ],
      "metadata": {
        "id": "vB_ikS5hS0W6"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input shape for the model"
      ],
      "metadata": {
        "id": "S_FyoAJuU2ZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = [len(vect.get_feature_names_out())]"
      ],
      "metadata": {
        "id": "NWfNTFDcUzvw"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to dense arrays"
      ],
      "metadata": {
        "id": "QWR92YyIS1JX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.toarray()\n",
        "X_test = X_test.toarray()"
      ],
      "metadata": {
        "id": "BG31fk8US4Wp"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Define the model"
      ],
      "metadata": {
        "id": "N-OHWpoOS7TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=input_shape),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "])\n"
      ],
      "metadata": {
        "id": "G_LJYzwcTHvA"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model"
      ],
      "metadata": {
        "id": "2pYvtT7yTMaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "QWj8_6xlTUSi"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "_8HBQIS2UBo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "J--lANZ9UFXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ],
      "metadata": {
        "id": "RtiPzmhjUO4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xKNzVXxUOHB",
        "outputId": "8640ae9b-1d11-48de-deac-f8a11b190b20"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.6691\n",
            "Loss:  0.6860483288764954\n",
            "Accuracy:  0.6690583229064941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print outputs"
      ],
      "metadata": {
        "id": "MUUEXwF2VgpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the feature names\n",
        "feature_names = vect.get_feature_names_out()\n",
        "\n",
        "# Print the first 100 words\n",
        "print(feature_names[:100])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxjeMeV5VheR",
        "outputId": "1b7e8828-0f5b-4932-9b38-dab305d3caaf"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['_' '____' 'aa' 'aah' 'aaniye' 'aaooooright' 'aathi' 'abbey' 'abdomen'\n",
            " 'abel' 'aberdeen' 'abi' 'ability' 'abiola' 'abj' 'able' 'abroad'\n",
            " 'absolutly' 'abstract' 'abt' 'abta' 'aburo' 'abuse' 'ac' 'academic' 'acc'\n",
            " 'accept' 'access' 'accessible' 'accident' 'accidentally' 'accommodation'\n",
            " 'accommodationvouchers' 'accomodate' 'accomodations' 'accordingly'\n",
            " 'account' 'accounting' 'accounts' 'achan' 'ache' 'achieve' 'acid'\n",
            " 'acknowledgement' 'acnt' 'aco' 'act' 'acted' 'actin' 'acting' 'action'\n",
            " 'activate' 'active' 'activities' 'actor' 'actual' 'actually' 'ad' 'adam'\n",
            " 'add' 'addamsfa' 'added' 'addicted' 'addie' 'address' 'adewale' 'adi'\n",
            " 'adjustable' 'admin' 'admirer' 'admission' 'admit' 'adore' 'adoring'\n",
            " 'adress' 'adrian' 'ads' 'adsense' 'adult' 'advance' 'adventure' 'advice'\n",
            " 'advise' 'advising' 'advisors' 'aeronautics' 'aeroplane' 'afew' 'affair'\n",
            " 'affairs' 'affection' 'affectionate' 'affections' 'affidavit' 'afford'\n",
            " 'afghanistan' 'afraid' 'africa' 'african' 'aft']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the weights of the first layer\n",
        "weights = model.layers[0].get_weights()[0]\n",
        "\n",
        "# Get the indices of the weights corresponding to the highest and lowest values\n",
        "# These would correspond to the features (words) that the model pays most and least attention to\n",
        "top_indices = weights.argsort(axis=0)[-10:]\n",
        "bottom_indices = weights.argsort(axis=0)[:10]\n",
        "\n",
        "# Get the feature names\n",
        "feature_names = vect.get_feature_names_out()\n",
        "\n",
        "# Print the words corresponding to the highest and lowest weights\n",
        "print(\"Words with highest weights:\")\n",
        "for i in top_indices:\n",
        "    print(feature_names[i])\n",
        "\n",
        "print(\"\\nWords with lowest weights:\")\n",
        "for i in bottom_indices:\n",
        "    print(feature_names[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbiB6_y4XXSA",
        "outputId": "9db99758-bec7-4661-e2e8-c3497c0af5fa"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words with highest weights:\n",
            "['warm' 'computational' 'fetching' 'dollars' 'mah' 'thinl' 'matthew'\n",
            " 'rajini' 'smidgin' 'gua' 'boston' 'woods' 'series' 'munsters' 'wiv'\n",
            " 'football' 'intentions' 'huge' 'created' 'barring' 'upset' 'confirmed'\n",
            " 'atten' 'said' 'evn' 'august' 'soundåõs' 'hear' 'india' 'paying' 'cried'\n",
            " 'gimme' 'dignity' 'ip' 'pg' 'index' 'straight' 'arestaurant' 'male' 'wld'\n",
            " 's' 'neck' 'cya' 'gving' 'text' 'unfortunately' 'smsrewards' 'defer'\n",
            " 'crowd' 'veggie' 'yuou' 'smth' 'nose' 'speed' 'gei' 'eppolum' 'atm'\n",
            " 'dino' 'normally' 'qlynnbv' 'ntimate' 'fever' 'lar' 'dieting']\n",
            "['varaya' 'vpod' 'scenario' 'internet' 'serving' 'honeymoon' 'mentioned'\n",
            " 'stranger' 'chechi' 'past' 'clark' 'lovly' 'renewed' 'cyclists' 'bw'\n",
            " 'bros' 'anjola' 'sec' 'demand' 'fffff' 'solved' 'sue' 'lavender' 'hussey'\n",
            " 'spys' 'immediately' 'scream' 'trackmarque' 'hamster' 'told' 'waitin'\n",
            " 'borderline' 'kochi' 'tomeandsaid' 'pros' 'support' 'en' 'center' 'blood'\n",
            " 'hannaford' 'spontaneously' 'yalru' 'monday' 'points' 'baaaaaaaabe'\n",
            " 'fucks' 'works' 'mf' 'opposite' 'doing' 'suits' 'present' 'complacent'\n",
            " 'mee' 'vco' 'rcb' 'near' 'snd' 'premium' 'mood' 'nosh' 'paying' 'bam'\n",
            " 'daily']\n",
            "['uve' 'digital' 'joining' 'shelves' 'netflix' 'drunkard' 'sends'\n",
            " 'differences' 'belongs' 'miserable' 'olayiwola' 'labor' 'immediately'\n",
            " 'replied' 'fixd' 'unknown' 'outta' 'unfortuntly' 'weather' 'lttrs'\n",
            " 'patty' 'idew' 'voila' 'anyplaces' 'text' 'usually' 'smsing' 'page'\n",
            " 'umma' 'chill' 'buns' 'lucozade' 'star' 'played' 'jocks' 'sheet'\n",
            " 'sleepingwith' 'avo' 'elaborating' 'available' 'associate' 'restrict'\n",
            " 'dirtiest' 'panties' 'blake' 'hu' 'attributed' 'saibaba' 'ros' 'xin'\n",
            " 'dined' 'differ' 'browse' 'permission' 'mobsi' 'late' 'sha' 'abroad' 'qi'\n",
            " 'jul' 'qbank' 'push' 'owl' 'samantha']\n",
            "['alcohol' 'weak' 'tarot' 'nìâte' 'strike' 'ramaduth' 'q' 'benefits'\n",
            " 'crore' 'remembrs' 'breathe' 'lady' 'cruel' 'specs' 'rt' 'iphone' 'mint'\n",
            " 'skyving' 'recreation' 'involve' 'offcampus' 'hasbro' 'bslvyl' 'bathroom'\n",
            " 'reserves' 'inst' 'fast' 'ultimate' 'visionsms' 'genuine' 'peril'\n",
            " 'isaiah' 'forums' 'escape' 'ws' 'slp' 'employer' 'arty' 'dead' 'forgets'\n",
            " 'tocall' 'dogg' 'countinlots' 'neighbors' 'mummy' 'fringe' 'smoothly'\n",
            " 'female' 'sometme' 'scraped' 'bathing' 'patients' 'shijutta' 'decent'\n",
            " 'frnt' 'glorious' 'beneath' 'cyclists' 'commercial' 'txtstar' 'delhi'\n",
            " 'crashing' 'fetch' 'minor']\n",
            "['updat' 'girlie' 'mango' 'doggin' 'rakhesh' 'price' 'stated' 'remembered'\n",
            " 'haunt' 'laugh' 'sugardad' 'tuition' 'acid' 'gals' 'piss' 'univ'\n",
            " 'matters' 'usual' 'û_thanks' 'italian' 'ûò' 'velusamy' 'carlos' 'sony'\n",
            " 'www' 'everyday' 'present' 'jiayin' 'ofå' 'compensation' 'thy' 'yup'\n",
            " 'nah' 'start' 'loan' 'embarassing' 'smiles' 'fancy' 'permissions' 'swat'\n",
            " 'pack' 'sppok' 'speed' 'opposed' 'content' 'renewing' 'playing' 'lodging'\n",
            " 'nails' 'collages' 'toplay' 'tantrum' 'mca' 'fri' 'stars' 'jolly'\n",
            " 'provided' 'outsider' 'kz' 'siva' 'hill' 'esplanade' 'entry' 'murder']\n",
            "['viva' 'labor' 'univ' 'plum' 'repair' 'ocean' 'crazyin' 'texting' 'poem'\n",
            " 'sue' 'stopped' 'haf' 'miracle' 'outbid' 'barred' 'kingdom' 'official'\n",
            " 'erode' 'harish' 'velachery' 'iam' 'wifes' 'optout' 'neighbour' 'lose'\n",
            " 'world' 'rentl' 'wounds' 'prin' 'closes' 'handed' 'holiday' 'planet'\n",
            " 'onwards' 'specs' 'visit' 'flirt' 'iraq' 'unusual' 'gamestar' 'lit'\n",
            " 'wisheds' 'guaranteed' 'lick' 'avble' 'woken' 'bein' 'hospital' 'alibi'\n",
            " 'recognise' 'joining' 'werebored' 'lifeis' 'spun' 'members' 'urfeeling'\n",
            " 'scary' 'mates' 'donno' 'boys' 'alright' 'pale' 'anand' 'kano']\n",
            "['film' 'cutting' 'kills' 'whore' 'dent' 'yam' 'netvision' 'biola' 'clock'\n",
            " 'coupla' 'cribbs' 'ericson' 'umma' 'clearly' 'determined' 'rats' 'dino'\n",
            " 'lou' 'images' 'andros' 'med' 'lyf' 'fffff' 'characters' 'shelf'\n",
            " 'renewing' 'escalator' 'blanket' 'command' 'cdgt' 'beerage' 'whore'\n",
            " 'holding' 'mobno' 'randomly' 'costa' 'liver' 'olympics' 'steam' 'aiyah'\n",
            " 'feed' 'wud' 'gentle' 'amla' 'masteriastering' 'prin' 'bw' 'forums'\n",
            " 'plate' 'discuss' 'sheet' 'marandratha' 'whr' 'posted' 'instructions'\n",
            " 'costa' 'org' 'celeb' 'buffet' 'mornin' 'acnt' 'askin' 'bec' 'fm']\n",
            "['superb' 'dogwood' 'infections' 'readiness' 'corporation' 'ese'\n",
            " 'question' 'desires' 'goodfriend' 'island' 'wants' 'iriver' 'meals'\n",
            " 'handed' 'accounting' 'panasonic' 'wondar' 'pillows' 'ridden' 'adore'\n",
            " 'comfey' 'hiya' 'responce' 'poor' 'sore' 'past' 'dare' 'log' 'emailed'\n",
            " 'awkward' 'franxx' 'short' 'hcl' 'registration' 'uk' 'burger' 'upgrade'\n",
            " 'slo' 'bringing' 'nora' 'bored' 'homeowners' 'rock' 'comprehensive'\n",
            " 'initiate' 'incorrect' 'purple' 'rents' 'woken' 'dedicated' 'weightloss'\n",
            " 'aco' 'archive' 'nxt' 'play' 'begun' 'arms' 'topic' 'stylish' 'flowing'\n",
            " 'vomiting' 'sehwag' 'anymore' 'work']\n",
            "['relocate' 'belligerent' 'straight' 'telling' 'num' 'sis' 'river'\n",
            " 'thursday' 'peoples' 'subs' 'persian' 'handed' 'awaiting' 'wid' 'post'\n",
            " 'gently' 'frndshp' 'mathe' 'trash' 'btw' 'sacked' 'wellda' 'ö' 'fat'\n",
            " 'stomach' 'onum' 'aspects' 'strain' 'cuz' 'ignorant' 'norcorp'\n",
            " 'unemployed' 'checkboxes' 'phasing' 'lonely' 'rate' 'women' 'tlk' 'blank'\n",
            " 'inclusive' 'claire' 'accounting' 'iåõm' 'pap' 'caroline' 'comment' 'rcd'\n",
            " 'dice' 'talks' 'wales' 'wear' 'bcz' 'ended' 'clover' 'fifa' 'mathews'\n",
            " 'prediction' 'objection' 'prospects' 'jam' 'wo' 'epsilon' 'textin'\n",
            " 'working']\n",
            "['hrishi' 'c' 'stayin' 'tis' 'headache' 'fm' 'dialogue' 'jaykwon' 'dobby'\n",
            " 'lodge' 'uworld' 'ivatte' 'txting' 'champneys' 'rencontre' 'tactful'\n",
            " 'messenger' 'jot' 'tmr' 'shola' 'drove' 'killing' 'antelope' 'training'\n",
            " 'web' 'touched' 'tool' 'classmates' 'run' 'gals' 'soonlots' 'ultimatum'\n",
            " 'surfing' 'superior' 'appeal' 'piss' 'sympathetic' 'swashbuckling'\n",
            " 'recycling' 'fixed' 'mandan' 'mmmmmm' 'waht' 'sorting' 'grandfather'\n",
            " 'pix' 'blow' 'dead' 'neighbors' 'ertini' 'asssssholeeee' 'sweet'\n",
            " 'undrstndng' 'shake' 'cornwall' 'bailiff' 'corrupt' 'miles' 'mf' 'juz'\n",
            " 'game' 'requests' 'lyk' 'surprise']\n",
            "\n",
            "Words with lowest weights:\n",
            "['upto' 'gender' 'blood' 'himso' 'themed' 'ths' 'min' 'person' 'midnight'\n",
            " 'mee' 'arng' 'dracula' 'mayb' 'tonght' 'salesman' 'ridden' 'smart'\n",
            " 'means' 'pax' 'jane' 'triumphed' 'salon' 'fridays' 'leh' 'yup' 'giv'\n",
            " 'helpful' 'playing' 'subscribe' 'adjustable' 'musthu' 'classic' 'omw' 'p'\n",
            " 'pleased' 'built' 'phones' 'tho' 'visionsms' 'freaking' 'eighth'\n",
            " 'esplanade' 'havent' 'tiring' 'flim' 'shortage' 'fees' 'beauty' 'batt'\n",
            " 'research' 'lovely' 'party' 'fav' 'taylor' 'happens' 'poop' 'sunscreen'\n",
            " 'bird' 'promise' 'telly' 'haul' 'mobs' 'officer' 'anand']\n",
            "['connections' 'fps' 'drugdealer' 'process' 'assume' 'marking' 'desires'\n",
            " 'aig' 'freaked' 'splat' 'doubt' 'hairdressers' 'urgent' 'invention'\n",
            " 'wounds' 'juswoke' 'muchand' 'arrival' 'strike' 'completely' 'fren'\n",
            " 'conacted' 'tasts' 'clubsaisai' 'aunt' 'kath' 'turns' 'ml' 'lyrics'\n",
            " 'chex' 'brum' 'like' 'ami' 'housework' 'wildest' 'expired' 'asus' 'model'\n",
            " 'colin' 'missunderstding' 'themed' 'reflex' 'professors' 'challenge'\n",
            " 'kadeem' 'disc' 'rentl' 'wid' 'cld' 'beehoon' 'pounded' 'paining'\n",
            " 'teletext' 'racing' 'takin' 'lionp' 'orno' 'eatin' 'tuition' 'sack'\n",
            " 'overdose' 'old' 'realize' 'uneventful']\n",
            "['rahul' 'yi' 'b' 'forums' 'nottingham' 'comb' 'uneventful' 'contact'\n",
            " 'cruel' 'nora' 'pmt' 'blocked' 'citylink' 'difficulties' 'stomach'\n",
            " 'noiåõm' 'dileep' 'fwiw' 'shit' 'dps' 'april' 'disc' 'hottest' 'holiday'\n",
            " 'sao' 'recharge' 'busty' 'longer' 'building' 'asusual' 'calculated'\n",
            " 'hero' 'rocks' 'nora' 'breeze' 'okmail' 'keypad' 'mustprovide' 'iraq'\n",
            " 'westshore' 'meow' 'responsible' 'embarassed' 'files' 'medical' 'feb'\n",
            " 'liver' 'amrita' 'mca' 'hesitation' 'lady' 'anot' 'reflex' 'cheaper'\n",
            " 'ttyl' 'watr' 'persons' 'alle' 'making' 'breadstick' 'buff' 'positive'\n",
            " 'thanksgiving' 'seeing']\n",
            "['toplay' 'tayseer' 'fuelled' 'shld' 'jenny' 'suite' 'manchester' 'maths'\n",
            " 'survey' 'mmmmmm' 'promoting' 'jo' 'cann' 'added' 'derek' 'breaks'\n",
            " 'backdoor' 'embarrassed' 'success' 'massive' 'suggest' 'moral' 'sight'\n",
            " 'ard' 'antha' 'spam' 'fails' 'norcorp' 'bought' 'ayn' 'pan' 'sem'\n",
            " 'visionsms' 'wisheds' 'link' 'parco' 'contacted' 'curious' 'nat' 'garden'\n",
            " 'cutie' 'tiring' 'photos' 'rtf' 'sed' 'fees' 'lighters' 'likely' 'bone'\n",
            " 'porn' 'posh' 'gaze' 'ajith' 'evrydy' 'velusamy' 'tobed' 'gre' 'shanil'\n",
            " 'jeremiah' 'pairs' 'prakasamanu' 'chip' 'tats' 'byatch']\n",
            "['prescription' 'wewa' 'whassup' 'page' 'tobed' 'favourite' 'lotto'\n",
            " 'baaaaaaaabe' 'fishrman' 'pro' 'lemme' 'dying' 'feng' 'prometazine'\n",
            " 'demand' 'basq' 'trip' 'extract' 'gayle' 'tenerife' 'mon' 'argentina'\n",
            " 'alrite' 'weird' 'school' 'mth' 'optin' 'luck' 'various' 'eng' 'bilo'\n",
            " 'cable' 'propose' 'putting' 'whispers' 'amma' 'combine' 'dd' 'helpful'\n",
            " 'shows' 'wahala' 'hate' 'brothas' 'embarassing' 'virtual' 'dedicated'\n",
            " 'mobiles' 'feet' 'ttyl' 'bat' 'tc' 'lambda' 'taunton' 'ac' 'sura'\n",
            " 'iåõllspeak' 'ms' 'oblivious' 'enters' 'recession' 'kay' 'parties'\n",
            " 'phone' 'canada']\n",
            "['gotten' 'value' 'violence' 'cme' 'otside' 'fly' 'listen' 'portal'\n",
            " 'village' 'chat' 'rencontre' 'vpod' 'cost' 'ratio' 'batt' 'annoying'\n",
            " 'visitor' 'authorise' 'maxå' 'admission' 'computer' 'restrictions'\n",
            " 'geeeee' 'sweetest' 'wish' 'grumpy' 'digi' 'tried' 'vic' 'commercial'\n",
            " 'cough' 'thread' 'sense' 'thousands' 'center' 'marriage' 'thirunelvali'\n",
            " 'authorise' 'directly' 'somtimes' 'dogbreath' 'amrita' 'replacing' 'ö'\n",
            " 'forgets' 'aroundn' 'prepaid' 'lie' 'tcs' 'disturbing' 'hey' 'icon'\n",
            " 'fridge' 'jack' 'virgin' 'hell' 'nope' 'ooooooh' 'click' 'torch'\n",
            " 'gaytextbuddy' 'boat' 'adress' 'shinco']\n",
            "['poo' 'drugs' 'gt' 'registration' 'trishul' 'weekends' 'maretare'\n",
            " 'forgets' 'manda' 'despite' 'tiwary' 'office' 'ö' 'tightly' 'chillaxin'\n",
            " 'd' 'bilo' 'iwas' 'disasters' 'internal' 'chatter' 'filled' 'efreefone'\n",
            " 'pert' 'bother' 'ages' 'buttons' 'maruti' 'definitly' 'juswoke'\n",
            " 'possession' 'declare' 'express' 'ducking' 'don' 'fear' 'walkin'\n",
            " 'intrepid' 'shanil' 'certainly' 'parchi' 'concern' 'involve'\n",
            " 'trackmarque' 'openings' 'digi' 'confidence' 'vu' 'kingdom'\n",
            " 'implications' 'hail' 'trouble' 'exam' 'goss' 'apps' 'swtheart' 'zac'\n",
            " 'nav' 'videos' 'dependents' 'paid' 'yor' 'finishes' 'gudnyt']\n",
            "['heads' 'bowa' 'neighbors' 'gayle' 'cheered' 'ar' 'tahan' 'delivered'\n",
            " 'info' 'rolled' 'case' 'farrell' 'oclock' 'lips' 'toxic' 'walked' 'nat'\n",
            " 'twinks' 'affection' 'opted' 'nannys' 'cya' 'bb' 'syria' 'award' 'reward'\n",
            " 'shldxxxx' 'knows' 'ibh' 'believe' 'outbid' 'atlast' 'gloucesterroad'\n",
            " 'ogunrinde' 'del' 'yelling' 'cha' 'payasam' 'dismay' 'store' 'cramps'\n",
            " 'ipad' 'alertfrom' 'small' 'daily' 'addie' 'shuhui' 'semi' 'deleted'\n",
            " 'kicks' 'posting' 'biola' 'twinks' 'spotty' 'passable' 'brother'\n",
            " 'smoothly' 'neva' 'loosing' 'soul' 'deeraj' 'obedient' 'likely' 'howard']\n",
            "['pg' 'buying' 'fuckinnice' 'tickets' 'mite' 'sunoco' 'reflex' 'suply'\n",
            " 'known' 'auction' 'london' 'wisdom' 'strt' 'hide' 'ecstacy' 'duo' 'bhaji'\n",
            " 'gaps' 'mandan' 'blow' 'near' 'hee' 'yorge' 'bros' 'nonetheless'\n",
            " 'associate' 'disturb' 'yoville' 'ger' 'misss' 'writhing' 'goodnight'\n",
            " 'monoc' 'lanka' 'prob' 'flirtparty' 'dormitory' 'eire' 'treacle' 'loko'\n",
            " 'fried' 'discuss' 'housewives' 'arithmetic' 'comedy' 'chapter' 'dime'\n",
            " 'legal' 'biz' 'sheet' 'dreading' 'sept' 'nanny' 'spam' 'kind' 'sweet'\n",
            " 'yoga' 'ridden' 'll' 'shade' 'childish' 'embassy' 'pictures' 'block']\n",
            "['console' 'scrounge' 'causes' 'studyn' 'urgent' 'involve' 'pert'\n",
            " 'digital' 'veggie' 'eating' 'nalla' 'odi' 'island' 'moan' 'basketball'\n",
            " 'bone' 'scenario' 'pdate_now' 'def' 'dbuk' 'players' 'undrstnd' 'muht'\n",
            " 'lib' 'ringtoneåá' 'answerin' 'lodge' 'jersey' 'charge' 'athome'\n",
            " 'convincing' 'mittelschmertz' 'meaning' 'ceri' 'reverse' 'ok' 'aburo'\n",
            " 'dogging' 'cld' 'ashley' 'sumfing' 'swalpa' 'hill' 'drunken' 'combine'\n",
            " 'chapel' 'secretly' 'sleepin' 'anand' 'hands' 'del' 'watr' 'ideas'\n",
            " 'legitimat' 'thatåõs' 'touched' 'wouldn' 'amla' 'painful' 'anot'\n",
            " 'factory' 'cream' 'lv' 'shanghai']\n"
          ]
        }
      ]
    }
  ]
}